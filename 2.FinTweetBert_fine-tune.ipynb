{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (79.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# Install Hugging Face Transformers and PyTorch libraries\n",
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at StephanAkkerman/FinTwitBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#1. Load the pre-trained FinTwitBERT model and tokenizer\n",
    "\n",
    "# Import tokenizer and sentiment classification model class\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# Load the FinTwitBERT tokenizer, pre-trained on financial tweets\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"StephanAkkerman/FinTwitBERT\")\n",
    "\n",
    "# Load FinTwitBERT model adapted for sentiment classification with 3 labels: bullish, neutral, bearish\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"StephanAkkerman/FinTwitBERT\",\n",
    "    num_labels=3  # For bullish, bearish, neutral\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Load the dataset and prepare model/tokenizer for classification\n",
    "import pandas as pd # Import pandas for handling CSV data\n",
    "\n",
    "\n",
    "# Load the filtered dataset containing tweets and sentiment labels\n",
    "actual_df = pd.read_csv(\"filtered_dataset.csv\")\n",
    "# Extract tweets and labels from the dataset\n",
    "tweets = actual_df[\"tweet\"].tolist()\n",
    "labels = actual_df[\"sentiment\"].tolist()  # should be 0 = bullish, 1 = neutral, 2 = bearish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenize the tweet texts for input to the model\n",
    "\n",
    "# Tokenize the tweets with padding and truncation for uniform input size\n",
    "encodings = tokenizer(\n",
    "    tweets,\n",
    "    padding=True,           # Pad shorter tweets to the same length\n",
    "    truncation=True,        # Truncate longer tweets to the maximum length\n",
    "    max_length=64,          # Maximum number of tokens per tweet\n",
    "    return_tensors=\"pt\"     # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "# Convert sentiment labels to PyTorch tensor format\n",
    "import torch\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split the dataset into training, validation, and test sets \n",
    "# (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the full dataset into 70% training and 30% temporary (val + test), stratified by label\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    range(len(labels)), \n",
    "    test_size=0.3,      # 30% for validation and test\n",
    "    stratify=labels,    # Ensure class balance across splits to maintain label distribution\n",
    "    random_state=42     # Seed for reproducibility\n",
    ")\n",
    "# Split the 30% temp set into 15% validation and 15% test, stratified again\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, \n",
    "    test_size=0.5, \n",
    "    stratify=labels[temp_idx], # Maintain label distribution\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define a custom PyTorch Dataset to wrap tokenized tweets and labels\n",
    "from torch.utils.data import Dataset\n",
    "# Create a custom dataset class for tweet sentiment classification\n",
    "class TweetDataset(Dataset): \n",
    "    # Constructor\n",
    "    def __init__(self, encodings, labels, indices):\n",
    "        # Store only the subset of data defined by the given indices (train/val/test)\n",
    "        self.encodings = {k: v[indices] for k, v in encodings.items()}\n",
    "        self.labels = labels[indices]\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        # Return one sample as a dictionary with input IDs, attention mask, and label\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "# Create dataset objects for training, validation, and testing\n",
    "train_dataset = TweetDataset(encodings, labels, train_idx)\n",
    "val_dataset = TweetDataset(encodings, labels, val_idx)\n",
    "test_dataset = TweetDataset(encodings, labels, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
